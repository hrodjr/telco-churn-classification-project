{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d2c21f5",
   "metadata": {},
   "source": [
    "### This will be in the prepare module\n",
    "    _Check for and remove duplicates by customer_id. - None\n",
    "    \n",
    "    _Remove redundant columns: payment_type_id, internet_service_type_id, contract_type_id, & customer_id. - Completed\n",
    "        -Used the following to drop redundant columns\n",
    "        -df = df.drop(['payment_type_id', 'internet_service_type_id', 'contract_type_id', 'customer_id'], axis = 1)\n",
    "        -df.head(2)\n",
    "    \n",
    "    _Encode payment_type(Electronic check, Mailed check, Bank transfer (automatic), Credit card (automatic)), internet_service_type(DSL, Fiber, None), contract_type(Month-to-month, One year, Two year), gender(male/female), partner(yes/no), multiple_line(yes/no), device_protection(yes/no), tech_support(yes/no), streaming_tv(yes/no), streaming_movies(yes/no), paperless_billing, & churn (yes/no).\n",
    "    - gender is male(1) or not male(0)\n",
    "    - yes(1) no(0)\n",
    "    - payment, contract and service types (True = 1) (Fales = 0)\n",
    "    \n",
    "    _Check for nulls and fill (Fill in total_charges' blanks with 0). - Completed\n",
    "        -#find empty values. Tried isna, isnull, notna, notnull but did not shown any matches.\n",
    "            -df.eq(' ').sum()\n",
    "        -Used .replace to empty values with a 0 in total charges.\n",
    "            -df = df.replace({'total_charges': ' '}, 0)\n",
    "            -df.head()\n",
    "\n",
    "    _Convert total_charges to float64. - Completed\n",
    "        -#convert 'total_charges' to float and validate change.\n",
    "        - df['total_charges'] = df['total_charges'].astype(float)\n",
    "        - df.dtypes\n",
    "    \n",
    "    _Replace 'No phone service' & 'No internet service' with 'No'. - Completed\n",
    "        -df.replace(to_replace = 'No internet service', value = 'No')\n",
    "        -df.replace(to_replace = 'No phone service', value = 'No')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81cf1d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries\n",
    "import get_db\n",
    "import explore\n",
    "import prepare\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "\n",
    "import graphviz\n",
    "from graphviz import Graph\n",
    "\n",
    "#ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#sklearn imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515a33e9",
   "metadata": {},
   "source": [
    "# Plan\n",
    "\n",
    "    Goal: Identify feature(s) that cause the greatest churn.\n",
    "    \n",
    "    Churn rate is 26.5% (1869) of 7043 customers.\n",
    "    \n",
    "    Taking you through the data pipeline I will begin with acquiring the telcor data from the get_db.py module, prepare it using the prepare.py module, split the data and on through exploration. Using explore.py module I identified a set of features used to develop my initial hypothesis. Once cleaned I ran it through multivariate to compare features to help with testing the listed inital hypothesis. Each exploration will include takeaways that have led to preparing, cleaning ant testing of the data resulting in rejecting or failing to reject the final hypothesis.\n",
    "    \n",
    "    Features within my hypothesis have been split, tested and modeled in order to provide a recommendation on the final hypothesis in order to reduce churn rates based rejected or failed to reject of the hypothesis. \n",
    "    \n",
    "    I have also identified unknown variables that at a later time can be researched, developed and tested using this model to predict future churn.\n",
    "\n",
    "    My initial hypothesis are listed below:\n",
    "    \n",
    "    1. churn is dependent of whether or not customers are on fiber. (chi2)\n",
    "        - Null: churn is independent of whether or not a customer are on fiber.\n",
    "        - Alternate: churn is dependent of whether or not customers are on fiber.\n",
    "            NOTES from univariate TAKEAWAYS:\n",
    "                *****AND what internet services fiber customers have AND do they affect churn?\n",
    "                *****What are the monthly costs?\n",
    "                \n",
    "    2. tenure and monthly charges are linearly correlated (pearsonr)\n",
    "        - Null: tenure and monthly charges are not linearly correlated\n",
    "        - Alt: tenure and monthly charges are linearly correlated\n",
    "                \n",
    "    3. churn is dependent younger customers.(chi2)\n",
    "        - Null: churn is independent of younger customers.\n",
    "        - Alternate: churn is dependent younger customers.\n",
    "        \n",
    "    4. Are monthly charges different for older people(ttest)\n",
    "        N: The average monthly charges for older customers is no different than the population (monthly_charges_mean)\n",
    "        A: The average monthly charges for older customers are different than rest of the population.\n",
    "            \n",
    "    5. do older people churn more than younger people(ttest)\n",
    "        -avg churn for older customers is no different than the population (churn)\n",
    "        -avg churn for older customers is different thatn the pop\n",
    "    \n",
    "    6. churn dependent on autopayment.(chi2)\n",
    "        - Null: churn is independent of whether or not customes are enrolle in autopayment plan.\n",
    "        - Alternate: churn is dependent of whether or not customes are enrolle in autopayment plan.\n",
    "            \n",
    "    7. churn dependent on phone_service (951)(chi2)\n",
    "            - Null: churn is independent on phone services\n",
    "            - Alternate: churn is dependent on phone services\n",
    "            \n",
    "    FEATURES:\n",
    "    \n",
    "        *** fiber (YES), tenure (1 month), single (NO), senior citizen (NO), m2m (YES), autopayments (NO), phone_service (YES)\n",
    "\n",
    "    FINAL HYPOTHESIS (reject or fail to reject):\n",
    "\n",
    "        *** Customers who are young, not single, on fiber, has phone service, on m2m, and not enrolled in a autopayment plan are more likely to churn than those customers that do not fall in this category.\n",
    "        \n",
    "\n",
    "    Exploration:\n",
    "        1. Univariate\n",
    "        2. Bivariate\n",
    "        3. Multivariate\n",
    "\n",
    "    Modeling:\n",
    "        1. Decision Tree\n",
    "        2. Random Forrest\n",
    "        3. KNN\n",
    "        \n",
    "    Conclusion\n",
    "        In conclusion, we ran through the data pipeline, identified our initial hypothesis, split, tested and model our features that resulted in the following recommendations.\n",
    "        1.\n",
    "        2.\n",
    "        3.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6222369",
   "metadata": {},
   "source": [
    "# *Working code for project*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e2f680",
   "metadata": {},
   "source": [
    "# Acquire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de09ea1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = get_db.get_telco_data()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e190c6",
   "metadata": {},
   "source": [
    "#### Initial visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd642cae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "58fac2e8",
   "metadata": {},
   "source": [
    "##### TAKEAWAYS \n",
    "\n",
    "    -Related services:\n",
    "        *multiple_services relates to phone_services\n",
    "        *online_security, online_backup, device_protection, tech_support, streaming_tv, and streaming_movies related to internet services. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68bd44c2",
   "metadata": {},
   "source": [
    "# Clean/Prepare\n",
    "\n",
    "    - The prepare file is broke up by sections to identify at which stage of the pipeline that I decided to edit, alter, modify or delete colums, column names, data types, etc...and are identifed by notes within the code.\n",
    "\n",
    "    * Initial clean up was done just after initial visualization of raw data.\n",
    "    * all other decisions to modify the dataframe are annotated within the prepare.py module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30360207",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#added above to the prepare module.\n",
    "df = prepare.clean_data(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f71704e",
   "metadata": {},
   "source": [
    "# Split your data into train, validate, and test samples.\n",
    "\n",
    "    The resulting dataframes should be 3 samples:\n",
    "    \n",
    "        1. a dataframe for training the algorithms\n",
    "            * The train dataset is for training our models. We also perform our exploratory data analysis on train.\n",
    "            \n",
    "        2. a dataframe for validating the models developed on unseen data\n",
    "            *First, it is an \"out of sample\" dataset so that we can evaluate our models on unseen data to measure how well the model generalizes.\n",
    "            *Second, the validate set allows us to fine tune our hyperparameters.\n",
    "            \n",
    "        3. a dataframe for testing the best performing model to ensure the model is able to be generalized on a final set of unseen data not 'overfitting' train, a validate and a test, roughly a 70%:20%:10% split\n",
    "            *final out of sample dataset used to evaluate how well the models tuned on validate generalize on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ebf450",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the dataframe into three dataframes (train, validate, and test)\n",
    "train, validate, test = prepare.train_validate_test_split(df, 'churned')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff0450b",
   "metadata": {},
   "source": [
    "# Exploratory\n",
    "\n",
    "    1. Discover features, using  that have the largest impact on the target variable, i.e. provide the most information gain, drive the outcome. To discover patterns, to spot anomalies, to test hypotheses and to check assumptions\n",
    "        *The dataframe resulting from these functions should be one that is pre-processed, i.e. ready to be used in modeling.\n",
    "        *attributes are reduced to features, features are in a numeric form, there are no missing values, and continuous and/or ordered values are scaled to be unitless.\n",
    "        \n",
    "    2. Hypothesize: Form and document your initial hypotheses about how the predictors (independent variables, features, or attributes) interact with the target (y-value or dependent variable).\n",
    "    \n",
    "    3. Use visualization techniques to identify drivers and follow up with a statistical test, do so.\n",
    "    \n",
    "    4. Test Hypothesis (t-tests, correlation, chi-square, e.g.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb4a2f4",
   "metadata": {},
   "source": [
    "#### Univariate Stats\n",
    "\n",
    "    1. Descriptive stats, frequencies, histograms.    \n",
    "        * Explore the target variable.\n",
    "        * Explore the categorical/qualitative variables.\n",
    "        * Explore the continuous/quantitative variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d43e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29dd076e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#list all categorical variables and quatintative variables for exploration within the train df.\n",
    "cat_vars = ['fiber', 'm2m', 'is_senior', 'churned', 'not_single', 'phone_service',\n",
    "           'online_security', 'online_backup', 'device_protection', 'tech_support', 'autopayment']\n",
    "quant_vars = ['tenure', 'monthly_charges']\n",
    "#variable histograms\n",
    "explore.explore_univariate(train, cat_vars, quant_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb16e554",
   "metadata": {},
   "source": [
    "##### TAKEAWAYS\n",
    "    8/28/2021\n",
    "    Of the TRAIN data...\n",
    "    - 44.43% (1752) of customers are on fiber\n",
    "    - 54.78% (2160) of customers are m2m \n",
    "    - 82.7% (3261) of customers are not senior\n",
    "    - 26.53% (1046) of customers churned\n",
    "    - 46.79% (1845) of customers are not single\n",
    "    - is_male is an even distribution. DROPPED this column.\n",
    "    - Customers with a 'partner' similarly divided (47.6 & 52.6 respectively)\n",
    "    - Customers with 'dependents' account for 70.1%\n",
    "    - Customers with 'phone_service_ account' for 91%\n",
    "    - autopayment accounts for 56.81% (2240) of customers 43.19% (1703) are not on autopayment.\n",
    "    - phone and internet services will be used at a later time.\n",
    "    - average tenure 32.32%\n",
    "    - average monthly_charges 65.15%\n",
    "    \n",
    "    -Initial assessment during prepare stage of the pipeline.\n",
    "        - m2m - 2160 or 55%, 1 year - 811 or 21%, 2 year - 972 or 24%\n",
    "            *change contract type to m2m (yes or no) and drop one and two year contracts.\n",
    "            *assumption is that if it is not m2m plan all others are on a contract.\n",
    "        - payment type - change to autopayment and drop 'credit_card', 'bank_transfer', check' and 'e_check'\n",
    "        -interent type:\n",
    "            *change internet type to fiber (Yes or No).\n",
    "            *Because there was only 61 customers with no internet that churned as validated in the Bivariate stats below.\n",
    "            *assumption, based on hypothesis, is that a customer is on fiber or not on fiber. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b293c487",
   "metadata": {},
   "source": [
    "# Hypothesis Testing\n",
    "\n",
    "-If our p-value is less than 'alpha' we reject the null hypothesis, otherwise, we fail to reject the null hypothesis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cc41f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = .05\n",
    "\n",
    "#The p-value is the chance that we obtained the results we did (or would obtain more extreme results) due to chance if the null hypothesis is true.\n",
    "#If the null hypothesis is true, our t-scores will follow a normal distribution and will be centered around 0.\n",
    "#The one sample t-test lets us compare the mean for a specific subgroup against the population mean. (One featureb)\n",
    "#We can also use a t-test to compare the means between two different supgroups. (difference between two features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c85e0c3",
   "metadata": {},
   "source": [
    "### HYP\n",
    "\n",
    "1. churn is dependent of whether or not customers are on fiber. (chi2)\n",
    "        - Null: churn is independent of whether or not a customer are on fiber.\n",
    "        - Alternate: churn is dependent of whether or not customers are on fiber."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb01dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "observed = pd.crosstab(train.churned, train['fiber'])\n",
    "chi2, p, degf, expected = stats.chi2_contingency(observed)\n",
    "print('Observed\\n')\n",
    "print(observed.values)\n",
    "print('---\\nExpected\\n')\n",
    "print(expected)\n",
    "print('---\\n')\n",
    "print(f'chi^2 = {chi2:.4f}')\n",
    "print(f'p     = {p:.4f}')\n",
    "print(f'Is p value less than alpha? {p < alpha}')\n",
    "if p < alpha:\n",
    "    print('We reject the null')\n",
    "else:\n",
    "    print(\"we fail to reject the null\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da068a45",
   "metadata": {},
   "source": [
    "### Hyp\n",
    "\n",
    "2. tenure and monthly charges are linearly correlated (pearsonr)\n",
    "        - Null: tenure and monthly charges are not linearly correlated\n",
    "        - Alt: tenure and monthly charges are linearly correlated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5915a8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr, p = stats.pearsonr(train.tenure, train.monthly_charges)\n",
    "\n",
    "if p < alpha:\n",
    "    print(\"We reject the null hypothesis\")\n",
    "else:\n",
    "    print(\"We fail to reject the null hypothesis\")\n",
    "    \n",
    "corr, p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34dfc616",
   "metadata": {},
   "source": [
    "### Hyp\n",
    "\n",
    "3. churn is dependent younger customers\n",
    "        - Null: churn is independent of younger customers.\n",
    "        - Alternate: churn is dependent of younger customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c0673b",
   "metadata": {},
   "outputs": [],
   "source": [
    "observed = pd.crosstab(train.churned, train['is_senior'])\n",
    "chi2, p, degf, expected = stats.chi2_contingency(observed)\n",
    "print('Observed\\n')\n",
    "print(observed.values)\n",
    "print('---\\nExpected\\n')\n",
    "print(expected)\n",
    "print('---\\n')\n",
    "print(f'chi^2 = {chi2:.4f}')\n",
    "print(f'p     = {p:.4f}')\n",
    "print(f'Is p value less than alpha? {p < alpha}')\n",
    "if p < alpha:\n",
    "    print('We reject the null')\n",
    "else:\n",
    "    print(\"we fail to reject the null\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08c79d3",
   "metadata": {},
   "source": [
    "### Hyp\n",
    "\n",
    "4. Do you younger customers pay more then the older customers\n",
    "        N: The average monthly charges for younger customers is no different than the population (monthly_charges_mean)\n",
    "        A: The average monthly charges for younger customers are different than rest of the population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aceb4969",
   "metadata": {},
   "outputs": [],
   "source": [
    "older_monthly_charges = df[df.is_senior == 0].monthly_charges\n",
    "monthly_charges_mean = df.monthly_charges.mean()\n",
    "\n",
    "test_results = stats.ttest_1samp(older_monthly_charges, monthly_charges_mean)\n",
    "test_results\n",
    "\n",
    "print(f'Is p value less than alpha? {p < alpha}')\n",
    "if p < alpha:\n",
    "    print('We reject the null')\n",
    "else:\n",
    "    print(\"we fail to reject the null\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda96f00",
   "metadata": {},
   "source": [
    "5. do younger customers churn more than older customers?\n",
    "        -younger customer churn is no different than the older population (churn)\n",
    "        -younger customer churn is different than the older population (churn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94587a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "older_churn = df[df.is_senior == 0].churned\n",
    "churn_mean = df.churned.mean()\n",
    "\n",
    "test_results = stats.ttest_1samp(older_churn, churn_mean)\n",
    "test_results\n",
    "\n",
    "print(f'Is p value less than alpha? {p < alpha}')\n",
    "if p < alpha:\n",
    "    print('We reject the null')\n",
    "else:\n",
    "    print(\"we fail to reject the null\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03be59ed",
   "metadata": {},
   "source": [
    "6. Do single customers churn more than non single customers?\n",
    "        -Single customer churn is no different than the non single population.\n",
    "        -Single customer churn is different than the non single population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a260261f",
   "metadata": {},
   "outputs": [],
   "source": [
    "single = df[df.not_single == 0].churned\n",
    "non_single = df.churned.mean()\n",
    "\n",
    "test_results = stats.ttest_1samp(single, non_single)\n",
    "test_results\n",
    "\n",
    "print(f'Is p value less than alpha? {p < alpha}')\n",
    "if p < alpha:\n",
    "    print('We reject the null')\n",
    "else:\n",
    "    print(\"we fail to reject the null\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94747623",
   "metadata": {},
   "source": [
    "7. churn dependent on autopayment.\n",
    "        - Null: churn is independent of whether or not customes are enrolle in autopayment plan.\n",
    "        - Alternate: churn is dependent of whether or not customes are enrolle in autopayment plan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664660f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "observed = pd.crosstab(train.churned, train['autopayment'])\n",
    "chi2, p, degf, expected = stats.chi2_contingency(observed)\n",
    "print('Observed\\n')\n",
    "print(observed.values)\n",
    "print('---\\nExpected\\n')\n",
    "print(expected)\n",
    "print('---\\n')\n",
    "print(f'chi^2 = {chi2:.4f}')\n",
    "print(f'p     = {p:.4f}')\n",
    "print(f'Is p value less than alpha? {p < alpha}')\n",
    "if p < alpha:\n",
    "    print('We reject the null')\n",
    "else:\n",
    "    print(\"we fail to reject the null\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9f936b",
   "metadata": {},
   "source": [
    "8. churn dependent on phone_service (951)\n",
    "            - Null: churn is independent on phone services\n",
    "            - Alternate: churn is dependent on phone services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43cde83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "observed = pd.crosstab(train.churned, train['phone_service'])\n",
    "chi2, p, degf, expected = stats.chi2_contingency(observed)\n",
    "print('Observed\\n')\n",
    "print(observed.values)\n",
    "print('---\\nExpected\\n')\n",
    "print(expected)\n",
    "print('---\\n')\n",
    "print(f'chi^2 = {chi2:.4f}')\n",
    "print(f'p     = {p:.4f}')\n",
    "print(f'Is p value less than alpha? {p < alpha}')\n",
    "if p < alpha:\n",
    "    print('We reject the null')\n",
    "else:\n",
    "    print(\"we fail to reject the null\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80e48ce",
   "metadata": {},
   "source": [
    "9. Customers who are young, single, on fiber, has phone service, on m2m, and not enrolled in a autopayment plan are more likely to churn than those customers that do not fall in this category.\n",
    "\n",
    "    -N: Customers who are young, single, on fiber, has phone service, on m2m, and not enrolled in a autopayment plan are no different than the rest of the population\n",
    "        -A: Customers who are young, single, on fiber, has phone service, on m2m, and not enrolled in a autopayment plan is different than the rest of the population\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892a3cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "customer = train[(train.is_senior == 0) & (train.not_single == 0) & (train.fiber == 1) & (train.m2m == 1) & \n",
    "                 (train.phone_service == 1) & (train.autopayment == 0)]\n",
    "customer_churn = customer.churned\n",
    "churn = train.churned.mean()\n",
    "\n",
    "test_results = stats.ttest_1samp(customer_churn, churn)\n",
    "test_results\n",
    "\n",
    "print(f'Is p value less than alpha? {p < alpha}')\n",
    "if p < alpha:\n",
    "    print('We reject the null')\n",
    "else:\n",
    "    print(\"we fail to reject the null\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583da49f",
   "metadata": {},
   "source": [
    "#### Bivariate Stats\n",
    "\n",
    "    1. Plot the interaction of each variable with the target. \n",
    "    \n",
    "    2. Document takeaways.\n",
    "\n",
    "    3. Explore interation of independent variables using viz and/or hypothesis testing to address interdependence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a1fea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removed target 'churned'\n",
    "cat_vars = ['fiber', 'm2m', 'is_senior', 'not_single', 'phone_service','autopayment']\n",
    "quant_vars = ['tenure', 'monthly_charges']\n",
    "explore.explore_bivariate(train, 'churned', cat_vars, quant_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78beafd4",
   "metadata": {},
   "source": [
    "##### TAKEAWAYS\n",
    "    8/28/2021\n",
    "    \n",
    "  -ON ALL Trained data\n",
    "  \n",
    "     - Number of fiber (728)  customers who churned.\n",
    "       * what is about our fiber internet service is making customers churn?\n",
    "       * Less people churn on DSL (257) then on fiber...possible validation that fiber service needs work.\n",
    "       * DROP no_internet. Only 61 customers who do not have internet churn.\n",
    "       HYPOTHESIS: Customers on fiber are more likely to churn than those customers not on fiber. ****convert Fiber and DSL into one column - Fiber(Yes or No) and encode.\n",
    "       *****AND what internet services fiber customers have AND do they affect churn.\n",
    "       * The new fiber becomes a feature\n",
    "       * test hyp\n",
    "\n",
    "    - 90.5% (929/1231) of customers in the first month churn than any other month\n",
    "        HYPOTHESIS: Customers are more than likely to churn in the first month of service than any other customer.\n",
    "        \n",
    "    - senior_citizen:\n",
    "        HYPOTHESIS: Customers who are NOT senior citizens (765) are more likely to churn than senior citizens (281).\n",
    " \n",
    "    - Between 'partner' and 'dependents' less single (no_d_863-no_p_687=176) customers churn then not single people (p_359 + d_183 = 542).\n",
    "    \n",
    "    - Phone service:\n",
    "        HYPOTHESIS: Customers with phone_service (951) are more likely to churn than those that do not have phone_service?\n",
    "            ***DROP multiple_lines. It is evenly weighed and does not have an impact on phone_services.\n",
    "            \n",
    "    - Interent services: DROP streaming services. Streaming services are eveningly weighed and will not affect intenert services and churn.\n",
    "        \n",
    "    - Payment type:\n",
    "        * converted payment type to autopayment (Yes or No). Assumption is that customers are either on or not on an autopayment plan.can I call you\n",
    "        HYPOTHESIS: Customers enrolled in automatic payment plan (266) are less likely to churn than those customers NOT enrolled in the automatic payment plan (780).\n",
    "\n",
    "    - Lower tenure more churn.\n",
    "    - Higher monthly payments more churn.\n",
    "\n",
    "  \n",
    "    \n",
    "    - Contract type:\n",
    "        * combine  m2m, 1, and 2 year contracts to a single column titled 'm2m' and encode.\n",
    "        HYPOTHESIS: m2m churn is greater than those customers not on m2m plan.\n",
    "        ---------------------------------------------\n",
    "    QUESTIONS:\n",
    "        1. Why do customers on fiber churn more?\n",
    "        2. Why do customers churn more in the first month than any other month?\n",
    "        3. Why do non single customers (with partner or dependents) churn more then single customers?\n",
    "        4. Why do younger customers churn more than older customers?\n",
    "        5. Why do customers on m2m plans churn more than those customers on contracts?\n",
    "        6. Why do customers enrolled in autopayments churn less than those customers not enrolled in an autopayment?\n",
    "        7. Why do customers churn more with phone services?\n",
    "        \n",
    "        * What do these questions all have in common?\n",
    "       ** What is the cost per month of a younger customers who is not single, has phone services and fiber, on a m2m plan, enrolled in an autopayment plan?\n",
    "       \n",
    "       *** FINAL HYPOTHESIS: Customers who are young, not single, on fiber, has phone service, on m2m, and not enrolled in a autopayment plan are more likely to churn than those customers that do not fall in this category.\n",
    "        \n",
    "        MY FEATURES: fiber (YES), tenure (1 month), single (NO), senior citizen (NO), m2m (YES), autopayments (NO), phone_service (YES)\n",
    "        \n",
    "        Test and validate HYPOTHESIS(reject or fail to reject final hypothesis)\n",
    "_________________________________________________\n",
    "\n",
    "\n",
    "Recommendation:???\n",
    "    _Churn in one month (213)_\n",
    "        * Incentive...\n",
    "            - 1 month free service for m2m customers?\n",
    "            - Free upgrade service for signing a one_year contract?\n",
    "            - Free premium service for two year contract?\n",
    "        * Create a graph that shows churn over tenure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2aae3d",
   "metadata": {},
   "source": [
    "#### Multivariate Stats\n",
    "\n",
    "    1. How subgroups compare to each-other and to the overall population. \n",
    "    \n",
    "    2. Answer questions using visualizations and/or hypothesis testing.\n",
    "    \n",
    "    (Here I can test some of my questions...reference Exploratory Analysis\n",
    "\n",
    "    _ Need to drop some columns for the multivariate stats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74447f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'churned'\n",
    "explore.explore_multivariate(train, target, cat_vars, quant_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d91ef02",
   "metadata": {},
   "source": [
    "##### TAKEAWAYS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6948841",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "056cf053",
   "metadata": {},
   "source": [
    "# Train, Validate, Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d048c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create X & y version of train, where y is a series with just the target variable and X are all the features.\n",
    "X_train = train[['fiber', 'm2m', 'is_senior', 'not_single', 'phone_service','autopayment']]#features\n",
    "y_train = train.churned#target\n",
    "\n",
    "X_validate = validate[['fiber', 'm2m', 'is_senior', 'not_single', 'phone_service','autopayment']]\n",
    "y_validate = validate.churned\n",
    "\n",
    "X_test = test[['fiber', 'm2m', 'is_senior', 'not_single', 'phone_service','autopayment']]\n",
    "y_test = test.churned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a645d2d",
   "metadata": {},
   "source": [
    "# Establish the baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a84efe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The mode is a great baseline\n",
    "baseline = y_train.mode()\n",
    "\n",
    "# Produce a boolean array with True representing a match between the baseline prediction and reality\n",
    "matches_baseline_prediction = y_train == 0\n",
    "\n",
    "baseline_accuracy = matches_baseline_prediction.mean()\n",
    "print(f\"Baseline accuracy: {round(baseline_accuracy, 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a108c0e5",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bd4d23",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2779954d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the model\n",
    "\n",
    "#for classification you can change the algorithm to gini or entropy (information gain).  \n",
    "#Default is gini.\n",
    "\n",
    "model = DecisionTreeClassifier(max_depth=4, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae337ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit the model\n",
    "\n",
    "model = model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0cbf61",
   "metadata": {},
   "source": [
    "#### Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffccfe27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the model\n",
    "\n",
    "# We'll evaluate the model's performance on train, first\n",
    "\n",
    "y_predictions = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3d6956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce the classification report on the actual y values and this model's predicted y values\n",
    "report = classification_report(y_train, y_predictions, output_dict=True)\n",
    "print(\"Tree of 4 depth\")\n",
    "pd.DataFrame(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314030cd",
   "metadata": {},
   "source": [
    "#### Estimate probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a113f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = model.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc40299a",
   "metadata": {},
   "source": [
    "#### Compute accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77736b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of Decision Tree classifier on training set: {:.2f}'\n",
    "      .format(model.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ab200f",
   "metadata": {},
   "source": [
    "#### Confusion matrix\n",
    "\n",
    "TP\n",
    "TN\n",
    "FP\n",
    "FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1601e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_train, y_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a666cf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089ff62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = sorted(y_train.unique())\n",
    "\n",
    "pd.DataFrame(confusion_matrix(y_train, y_predictions), index=labels, columns=labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6137a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_train, y_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e94fda",
   "metadata": {},
   "source": [
    "#### Evaluate the Model with our Validate dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3446adaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of Decision Tree classifier on validate set: {:.2f}'\n",
    "     .format(model.score(X_validate, y_validate)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf21a3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And since accuracy isn't everything\n",
    "\n",
    "# Produce y_predictions that come from the X_validate\n",
    "y_pred = model.predict(X_validate)\n",
    "\n",
    "# Compare actual y values (from validate) to predicted y_values from the model run on X_validate\n",
    "print(classification_report(y_validate, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3186d7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce the classification report on the actual y values and this model's predicted y values\n",
    "report = classification_report(y_train, y_predictions, output_dict=True)\n",
    "print(\"Tree of 1 depth\")\n",
    "pd.DataFrame(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547b6a1f",
   "metadata": {},
   "source": [
    "### Random Forrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a19aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the Model\n",
    "rf = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini', min_samples_leaf=1, n_estimators=10,\n",
    "                            max_depth=4, \n",
    "                            random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67316071",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit the Model\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27402cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the Model\n",
    "#evaluate the weight\n",
    "print(rf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90834024",
   "metadata": {},
   "outputs": [],
   "source": [
    "#estimate\n",
    "y_pred = rf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1adae52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#probability\n",
    "y_pred_proba = rf.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2bb01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy\n",
    "print('Accuracy of random forest classifier on training set: {:.2f}'.format(rf.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1014fbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix\n",
    "print(confusion_matrix(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907107ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a classificaiton report\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1d0fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of random forest classifier on test set: {:.2f}'.format(rf.score(X_validate, y_validate)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e621a0",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d052e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the model\n",
    "# weights = ['uniform', 'density']\n",
    "knn = KNeighborsClassifier(n_neighbors=5, weights='uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d34f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit the model\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57004d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict/use the model\n",
    "y_pred = knn.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc5642e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#probability\n",
    "y_pred_proba = knn.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c15f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy\n",
    "print('Accuracy of KNN classifier on training set: {:.2f}'.format(knn.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3d7eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix\n",
    "print(confusion_matrix(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16988733",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb82509",
   "metadata": {},
   "outputs": [],
   "source": [
    "#validate\n",
    "print('Accuracy of KNN classifier on test set: {:.2f}'.format(knn.score(X_validate, y_validate)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d25faf8",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "    - What we don't know:\n",
    "        * How plans relate to cost. i.e. phone to service plans\n",
    "        * How service plans (online security, online backup, tech support, device protection, and streaming services) relates to cost.\n",
    "        * Cost of one line, cost of multiple lines (what is multiple lines? Is it 2, 3, 4, or more) and how that relates to cost."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
